{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HEz-72rWMIYj",
    "outputId": "b7bf1492-0bca-4355-f6d6-26c2ce534fd6"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "410gYINs1gm4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!unzip /content/drive/MyDrive/Colab_Notebooks/8k_image_captioning.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "tQNbELEF1tRQ",
    "outputId": "39d6bd37-966e-4f57-a1e1-e7aa00156d84"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'progressbar'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d7d9b16cc566>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mprogressbar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'progressbar'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2 as op\n",
    "import progressbar\n",
    "from collections import Counter\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Input, add, Conv2D\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "import seaborn as sea\n",
    "from scipy import stats\n",
    "from keras import layers\n",
    "from os import listdir\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from pickle import dump, load\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vMfiOCgq13zA"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"captions.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "Cx4m_0ww18l6",
    "outputId": "391e72ba-8a77-4a9f-caf3-9e14f445e2f3"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vn_eFF2k1_vw",
    "outputId": "a169d672-19f6-41f1-f144-fbb592f1f757"
   },
   "outputs": [],
   "source": [
    "n_images = 8091\n",
    "n_captions = 40455\n",
    "8091 * 5 == 40455"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0Xx3ifojuX0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1V9VVCgBIwW"
   },
   "outputs": [],
   "source": [
    "base_model = MobileNet(input_shape = (224,224,3), include_top = True)\n",
    "x = Conv2D(filters = 512, kernel_size = (1,1), activation = 'sigmoid')(base_model.layers[-5].output)\n",
    "base_model = Model(inputs= base_model.inputs, outputs= x)\n",
    "base_model.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKKfS8ZrgG2C"
   },
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBcjDN9-5jwu"
   },
   "outputs": [],
   "source": [
    "def load_preprocess_image(path):\n",
    "    img = op.imread(path)\n",
    "    img = op.cvtColor(img, op.COLOR_BGR2RGB)\n",
    "    img = op.resize(img, (224,224))\n",
    "    img = img /255.0\n",
    "    img = img.reshape(1,224,224,3)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "9xdDcR_66hWO",
    "outputId": "94e3f9ac-7873-4c54-9b4c-5cea0a2d0c9b"
   },
   "outputs": [],
   "source": [
    "img = load_preprocess_image('/content/Images/1000268201_693b08cb0e.jpg')\n",
    "plt.imshow(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyhnY-Uw2N4M"
   },
   "outputs": [],
   "source": [
    "def extract_features(directory):\n",
    "    \n",
    "    # base_model = MobileNet(input_shape = (224,224,3), include_top = True)\n",
    "    # base_model = Model(inputs= base_model.inputs, outputs= base_model.layers[-5].output)\n",
    "    # base_model.training = False\n",
    "    # print(base_model.summary())\n",
    "    # print(base_model.output.shape)\n",
    "    features = dict()\n",
    "    \n",
    "    for i, name in enumerate(listdir(directory)):\n",
    "        img = load_preprocess_image(directory + \"/\" + name)\n",
    "        fvec = base_model.predict(img, verbose = 0)\n",
    "        features[name] = fvec\n",
    "\n",
    "        if((i+1) % 1000 == 0):\n",
    "            print((i+1),'Done')\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0TWi8YL52z6_",
    "outputId": "5f8faa33-93e9-4530-f4bd-10d0775653be"
   },
   "outputs": [],
   "source": [
    "DIR = '/content/Images'\n",
    "\n",
    "features = extract_features(DIR)\n",
    "\n",
    "# dump(features, open('features.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EUpVHe_5mIX"
   },
   "outputs": [],
   "source": [
    "dump(features, open('features.pkl', 'wb'))\n",
    "del features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MrJ_ZpkP9U6W"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(text_original):\n",
    "    text_no_punctuation = text_original.translate(str.maketrans('','',string.punctuation))\n",
    "    return(text_no_punctuation)\n",
    "\n",
    "def remove_numeric(text,printTF=False):\n",
    "    text_no_numeric = \"\"\n",
    "    for word in text.split():\n",
    "        isalpha = word.isalpha()\n",
    "        if printTF:\n",
    "            print(\"{:10} : {:}\".format(word,isalpha))\n",
    "        if isalpha:\n",
    "            text_no_numeric += \" \" + word\n",
    "    return(text_no_numeric)\n",
    "\n",
    "def lower_text(text):\n",
    "    return str(text).lower()\n",
    "\n",
    "def add_start_end(caption):\n",
    "    caps = []\n",
    "    for cap in caption:\n",
    "        cap = 'startseq' + cap + ' endseq'\n",
    "        caps.append(cap)\n",
    "    return caps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fh-FUe6l-wHu",
    "outputId": "0b539720-afd8-4c49-d46d-76927180089b"
   },
   "outputs": [],
   "source": [
    "def text_clean(text_original):\n",
    "    text = remove_punctuation(text_original)\n",
    "    text = remove_numeric(text)\n",
    "    text = lower_text(text)\n",
    "    return(text)\n",
    "\n",
    "with progressbar.ProgressBar(max_value=len(df.caption.values)) as bar:\n",
    "    for i, caption in enumerate(df.caption.values):\n",
    "        newcaption = text_clean(caption)\n",
    "        df[\"caption\"].iloc[i] = newcaption\n",
    "        bar.update(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-x7NJhbXEVa1"
   },
   "outputs": [],
   "source": [
    "df['caption'] = add_start_end(df['caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QOV7HwitErRV",
    "outputId": "b15e82c9-5a5f-40ad-a939-2d847d7ab937"
   },
   "outputs": [],
   "source": [
    "df['caption'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6obTajlA2e-"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_vocab_len():\n",
    "    vocabulary = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            temp = df.iloc[i,1]\n",
    "            vocabulary.extend(temp.split())\n",
    "        except:\n",
    "            print(i)\n",
    "\n",
    "    return len(set(vocabulary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J7Qy2aeuBFQt",
    "outputId": "812aca5b-1571-4a40-9923-3c00334a19f8"
   },
   "outputs": [],
   "source": [
    "n_vocab = get_vocab_len()\n",
    "n_vocab += 1\n",
    "print(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iR2zGZQ9_DPN"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(n_vocab)\n",
    "\n",
    "tokenizer.fit_on_texts(df['caption'].values)\n",
    "\n",
    "# tokenized_captions = tokenizer.texts_to_sequences(df['caption'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "diQ3bH1KAnpm"
   },
   "outputs": [],
   "source": [
    "word2idx = tokenizer.word_index\n",
    "word2idx['pad'] = 0\n",
    "idx2word = dict((idx, word) for (word, idx) in word2idx.items())\n",
    "\n",
    "def decode(seq):\n",
    "    return \" \".join([idx2word.get(idx, \"?\") for idx in seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0N-GSOOJROu"
   },
   "outputs": [],
   "source": [
    "def define_model(embedding_dim, seq_len, n_vocab):\n",
    "    img_input = Input(shape = (512,))\n",
    "    # fimg = base_model(img)\n",
    "    # fimg = Dense(512, activation = 'relu')(img_input)\n",
    "    # fimg = Dropout(0.2)(img_input)\n",
    "\n",
    "    txt_input = Input(shape = (seq_len, ))\n",
    "    txt = Embedding(n_vocab, embedding_dim, mask_zero = True)(txt_input)\n",
    "    txt = LSTM(512, return_sequences = True)(txt)\n",
    "    txt = Dropout(0.3)(txt)\n",
    "    txt = LSTM(512)(txt)\n",
    "\n",
    "    decoder = add([img_input, txt])\n",
    "    decoder = Dense(1500, activation = 'relu')(decoder)\n",
    "    decoder = Dropout(0.2)(decoder)\n",
    "\n",
    "    output = Dense(n_vocab, activation = 'softmax')(decoder)\n",
    "\n",
    "    model = Model(inputs = [img_input, txt_input], outputs = output)\n",
    "\n",
    "    model.compile(\n",
    "        loss = 'categorical_crossentropy', \n",
    "        optimizer =  keras.optimizers.Adam())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPJ3HI_ZJ1rs"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "seq_len = 6\n",
    "\n",
    "model = define_model(embedding_dim, seq_len, n_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypBDoTq9PyIU",
    "outputId": "9f51d5aa-2fd4-4c4e-d85f-4200cf6c0bfd"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ExeFnGaQFqMF"
   },
   "outputs": [],
   "source": [
    "\n",
    "all_features = load(open('/content/features.pkl', 'rb'))\n",
    "for key in all_features.keys():\n",
    "    all_features[key] = np.reshape(all_features[key], (512, ))\n",
    "    \n",
    "\n",
    "def create_sequences(captions, images, seq_len = 6):\n",
    "    X1, X2, y = [], [], []\n",
    "\n",
    "    for cap, img in zip(captions, images):\n",
    "        cap = cap.split()\n",
    "        # predicting each next word\n",
    "        # earlier window was selected and then next word was predicted\n",
    "        # problem observed was initial words were not predicted during testing, since they weren't predicted during training itself\n",
    "        for i in range(0, len(cap)-1):\n",
    "            in_seq = tokenizer.texts_to_sequences([cap[0 : i + 1]])\n",
    "            in_seq = pad_sequences(in_seq, maxlen = seq_len, padding = 'post')[0]\n",
    "            out_seq = word2idx[cap[i + 1]]\n",
    "            \n",
    "            if(sum(in_seq) == 0):\n",
    "                break\n",
    "            \n",
    "            X1.append(in_seq)\n",
    "            X2.append(all_features[img])\n",
    "            y.append(np_utils.to_categorical(out_seq, n_vocab))\n",
    "    \n",
    "    return np.array(X1), np.array(X2), np.array(y)\n",
    "\n",
    "def load_photo_features(filename, dataset):\n",
    "\t# load all features\n",
    "\tall_features = load(open(filename, 'rb'))\n",
    "\t# filter features\n",
    "\tfeatures = {k: all_features[k] for k in dataset}\n",
    "\treturn features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izLCioHlRJYs"
   },
   "outputs": [],
   "source": [
    "# def data_generator(data):\n",
    "#     i = 0 # Can be inialized to a random index and start the batch from that index cylically for each epoch\n",
    "#     while 1:\n",
    "#         x1, x2, y = create_sequences(data.iloc[i: i+ 29, 1], data.iloc[i : i + 29, 0], seq_len)\n",
    "#         i = (i + 29) % len(df)\n",
    "#         yield [[x2,x1], y]\n",
    "\n",
    "#randomized implementation\n",
    "def data_generator(data):\n",
    "    i = 0 # Can be inialized to a random index and start the batch from that index cylically for each epoch\n",
    "    while 1:\n",
    "        td = data.sample(n = batch_size)\n",
    "        x1, x2, y = create_sequences(td.iloc[:, 1], td.iloc[:, 0], seq_len)\n",
    "        # i = (i + 29) % len(df)\n",
    "        yield [[x2,x1], y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HyAxB7ldvKFA"
   },
   "outputs": [],
   "source": [
    "loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pqxWCF1hqOxw",
    "outputId": "8df8e4ff-d74a-4326-e8ff-3756ab5dc53b"
   },
   "outputs": [],
   "source": [
    "epochs = 5 # have to increase. On higher epochs, loss kept decreasing but prediction wasn't good. Performed better for fewer epochs.\n",
    "batch_size = 29\n",
    "steps = len(df)/batch_size # NO PROBLEM HERE\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(\"Epoch:\", i+1)\n",
    "    generator = data_generator(df)\n",
    "    model.fit(generator, epochs = 1, steps_per_epoch = steps)\n",
    "    loss.append(model.history.history['loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "mSS7_cjmYotb",
    "outputId": "473f634c-2f86-474a-903d-d138569da0e6"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(loss)) + 1, loss, '--r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MuTBWhiOFjwo",
    "outputId": "5aafce20-88a4-458f-aa37-e4a6dbd269c0"
   },
   "outputs": [],
   "source": [
    "model.save(\"model_v4_loss=1.5008.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8beemKNSANx2"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# model2 = load_model('/content/drive/MyDrive/Model/model_v4_loss=1.5008.h5')\n",
    "\n",
    "def predict_caption(image):\n",
    "    '''\n",
    "    image.shape = (1,4462)\n",
    "    '''\n",
    "    in_text = 'startseq'\n",
    "\n",
    "    for iword in range(30):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])\n",
    "        sequence = pad_sequences(sequence, maxlen = seq_len, padding = 'post')[0]\n",
    "        sequence = np.array(sequence).reshape(1, -1)\n",
    "    \n",
    "        yhat = model.predict([image,sequence],verbose=0)\n",
    "        yhat = np.argmax(yhat)\n",
    "        \n",
    "        newword = idx2word[yhat]\n",
    "        # print(newword)\n",
    "        in_text += \" \" + newword\n",
    "        \n",
    "        if newword == \"endseq\":\n",
    "            break\n",
    "            \n",
    "    return(in_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "HBJ7qGnDGrEb",
    "outputId": "e0772f2d-d669-46be-fa6a-97a2c0073cbe"
   },
   "outputs": [],
   "source": [
    "url = 'https://i.insider.com/5afc93865e48ec51008b458a?width=600&format=jpeg&auto=webp'\n",
    "import requests, io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "bytes_im = io.BytesIO(response.content)\n",
    "img = op.cvtColor(np.array(Image.open(bytes_im)), op.COLOR_BGR2RGB)\n",
    "\n",
    "img = op.resize(img, (224,224))\n",
    "img = op.cvtColor(img, op.COLOR_BGR2RGB)\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "img = img/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qX8V1vQQAZAO"
   },
   "outputs": [],
   "source": [
    "# test_path = '/content/45127963-young-black-man-working-in-construction-site.webp'\n",
    "# img = load_preprocess_image(test_path)\n",
    "\n",
    "img_vec = base_model.predict(img).reshape(1,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ppS9BOGWVmA",
    "outputId": "2351f317-5c8b-45c8-e136-2c9767dad83d"
   },
   "outputs": [],
   "source": [
    "img_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_2QBoINAwp-"
   },
   "outputs": [],
   "source": [
    "ans = predict_caption(img_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ppnBAJjuVybr",
    "outputId": "56b67b46-9e2d-4474-a522-4736f3e29ac2"
   },
   "outputs": [],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "awo4N2w7tVuK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "icDec1v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
